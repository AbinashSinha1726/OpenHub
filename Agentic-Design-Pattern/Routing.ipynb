{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7b8ece",
   "metadata": {},
   "source": [
    "# Steps \n",
    "\n",
    "User Query\n",
    "\n",
    "        â†“\n",
    "\n",
    "Router Agent (Intent + Constraints)\n",
    "\n",
    "        â†“\n",
    "\n",
    "Select Specialist Agent\n",
    "\n",
    "        â†“\n",
    "\n",
    "Specialist Agent Executes\n",
    "\n",
    "        â†“\n",
    "\n",
    "Final Response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2232b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Specialist Agents\n",
    "#Each agent has: Narrow scope, Clear responsibility, Simple interface (run(query))\n",
    "\n",
    "class CodeAgent:\n",
    "    def run(self, query):\n",
    "        print(f\"Code Agent called\")\n",
    "        return \"ðŸ§‘â€ðŸ’» CodeAgent: Generating code-related response\"\n",
    "\n",
    "\n",
    "class RAGAgent:\n",
    "    def run(self, query):\n",
    "        print(f\"RAG Agent called\")\n",
    "        return \"ðŸ“š RAGAgent: Answering using retrieved documents\"\n",
    "\n",
    "\n",
    "class DesignAgent:\n",
    "    def run(self, query):\n",
    "        print(f\"Design Agent called\")\n",
    "        return \"ðŸ—ï¸ DesignAgent: Creating system architecture\"\n",
    "\n",
    "\n",
    "class EvaluationAgent:\n",
    "    def run(self, query):\n",
    "        print(f\"Evaluation Agent called\")\n",
    "        return \"ðŸ“Š EvaluationAgent: Defining evaluation metrics\"\n",
    "\n",
    "\n",
    "class GeneralAgent:\n",
    "    def run(self, query):\n",
    "        print(f\"General Agent called\")\n",
    "        return \"ðŸ¤– GeneralAgent: Handling ambiguous request\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c08691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Router Agent \n",
    "# The router has : Classifies intent, Chooses best agent, Supports fallback\n",
    "\n",
    "class RouterAgent:\n",
    "    def __init__(self):\n",
    "        self.agents = {\n",
    "            \"code\": CodeAgent(),\n",
    "            \"rag\": RAGAgent(),\n",
    "            \"design\": DesignAgent(),\n",
    "            \"evaluation\": EvaluationAgent(),\n",
    "            \"general\": GeneralAgent()\n",
    "        }\n",
    "\n",
    "    def classify_intent(self, query: str) -> str:\n",
    "        query = query.lower()\n",
    "\n",
    "        if \"code\" in query or \"python\" in query:\n",
    "            return \"code\"\n",
    "        elif \"rag\" in query or \"retrieval\" in query:\n",
    "            return \"rag\"\n",
    "        elif \"architecture\" in query or \"design\" in query:\n",
    "            return \"design\"\n",
    "        elif \"evaluate\" in query or \"metrics\" in query:\n",
    "            return \"evaluation\"\n",
    "        else:\n",
    "            return \"general\"\n",
    "\n",
    "    def route(self, query: str):\n",
    "        intent = self.classify_intent(query)\n",
    "        return self.agents[intent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c756887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Engine\n",
    "\n",
    "def run_agentic_system(user_query):\n",
    "    router = RouterAgent()\n",
    "\n",
    "    agent = router.route(user_query)\n",
    "    response = agent.run(user_query)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7ee0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Agent called\n",
      "ðŸ§‘â€ðŸ’» CodeAgent: Generating code-related response\n"
     ]
    }
   ],
   "source": [
    "#Example Run\n",
    "\n",
    "#query = \"Design a RAG architecture and evaluation metrics\"\n",
    "query = \"Design a Python code architecture for addition of two number and evaluation metrics\"\n",
    "print(run_agentic_system(query))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717979e",
   "metadata": {},
   "source": [
    "# Routing Strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0c6b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Agent called\n",
      "ðŸ“š RAGAgent: Handling retrieval-based tasks\n"
     ]
    }
   ],
   "source": [
    "# Rule-based routing\n",
    "\n",
    "# -------------------------------\n",
    "# Specialist Agents\n",
    "# -------------------------------\n",
    "\n",
    "class CodeAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Code Agent called\")\n",
    "        return \"ðŸ§‘â€ðŸ’» CodeAgent: Handling code-related tasks\"\n",
    "\n",
    "\n",
    "class RAGAgent:\n",
    "    def run(self, query):\n",
    "        print(\"RAG Agent called\")\n",
    "        return \"ðŸ“š RAGAgent: Handling retrieval-based tasks\"\n",
    "\n",
    "\n",
    "class DesignAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Design Agent called\")\n",
    "        return \"ðŸ—ï¸ DesignAgent: Handling architecture/design tasks\"\n",
    "\n",
    "\n",
    "class EvaluationAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Evaluation Agent called\")\n",
    "        return \"ðŸ“Š EvaluationAgent: Handling evaluation & metrics\"\n",
    "\n",
    "\n",
    "class GeneralAgent:\n",
    "    def run(self, query):\n",
    "        print(\"General Agent called\")\n",
    "        return \"ðŸ¤– GeneralAgent: Handling ambiguous queries\"\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Router Agent (Rule-Based)\n",
    "# -------------------------------\n",
    "\n",
    "class RouterAgent:\n",
    "    def __init__(self):\n",
    "        self.agents = {   # Agent Registry\n",
    "            \"code\": CodeAgent(),\n",
    "            \"rag\": RAGAgent(),\n",
    "            \"design\": DesignAgent(),\n",
    "            \"evaluation\": EvaluationAgent(),\n",
    "            \"general\": GeneralAgent()\n",
    "        }\n",
    "#Intent Classification (Rules)\n",
    "    def classify_intent(self, query: str) -> str:\n",
    "        query = query.lower()\n",
    "#Rule Checks\n",
    "        if \"code\" in query or \"python\" in query:\n",
    "            return \"code\"\n",
    "        elif \"rag\" in query or \"retrieval\" in query:\n",
    "            return \"rag\"\n",
    "        elif \"architecture\" in query or \"design\" in query:\n",
    "            return \"design\"\n",
    "        elif \"evaluate\" in query or \"metrics\" in query:\n",
    "            return \"evaluation\"\n",
    "        else:\n",
    "            return \"general\"\n",
    "# Routing Logic\n",
    "    def route(self, query: str):\n",
    "        intent = self.classify_intent(query)\n",
    "        return self.agents[intent]\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Execution Engine\n",
    "# -------------------------------\n",
    "\n",
    "def run_agentic_system(user_query: str):\n",
    "    router = RouterAgent()\n",
    "    agent = router.route(user_query)\n",
    "    return agent.run(user_query)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Example Run\n",
    "# -------------------------------\n",
    "\n",
    "query = \"Design a RAG architecture and evaluation metrics\"\n",
    "response = run_agentic_system(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b361c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding-based routing\n",
    "\n",
    "class CodeAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Code Agent called\")\n",
    "        return \"ðŸ§‘â€ðŸ’» CodeAgent: Handling code-related tasks\"\n",
    "\n",
    "\n",
    "class RAGAgent:\n",
    "    def run(self, query):\n",
    "        print(\"RAG Agent called\")\n",
    "        return \"ðŸ“š RAGAgent: Handling retrieval-based tasks\"\n",
    "\n",
    "\n",
    "class DesignAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Design Agent called\")\n",
    "        return \"ðŸ—ï¸ DesignAgent: Handling architecture/design tasks\"\n",
    "\n",
    "\n",
    "class EvaluationAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Evaluation Agent called\")\n",
    "        return \"ðŸ“Š EvaluationAgent: Handling evaluation & metrics\"\n",
    "\n",
    "\n",
    "class GeneralAgent:\n",
    "    def run(self, query):\n",
    "        print(\"General Agent called\")\n",
    "        return \"ðŸ¤– GeneralAgent: Handling ambiguous queries\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e11f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding-Based Router\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "class EmbeddingRouter:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "        self.agents = {\n",
    "            \"code\": CodeAgent(),\n",
    "            \"rag\": RAGAgent(),\n",
    "            \"design\": DesignAgent(),\n",
    "            \"evaluation\": EvaluationAgent(),\n",
    "            \"general\": GeneralAgent()\n",
    "        }\n",
    "\n",
    "        # Agent intent descriptions\n",
    "        self.agent_descriptions = {\n",
    "            \"code\": \"writing programming code, python, debugging, implementation\",\n",
    "            \"rag\": \"retrieval augmented generation, documents, vector databases, search\",\n",
    "            \"design\": \"system design, architecture diagrams, scalable systems\",\n",
    "            \"evaluation\": \"metrics, evaluation, benchmarking, accuracy, performance\",\n",
    "            \"general\": \"general or unclear requests\"\n",
    "        }\n",
    "\n",
    "        # Precompute embeddings\n",
    "        self.agent_embeddings = {\n",
    "            intent: self.model.encode(desc, convert_to_tensor=True)\n",
    "            for intent, desc in self.agent_descriptions.items()\n",
    "        }\n",
    "\n",
    "    def route(self, query: str):\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        scores = {}\n",
    "        for intent, emb in self.agent_embeddings.items():\n",
    "            similarity = util.cos_sim(query_embedding, emb).item()\n",
    "            scores[intent] = similarity\n",
    "\n",
    "        best_intent = max(scores, key=scores.get)\n",
    "        return self.agents[best_intent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5bcbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Engine\n",
    "\n",
    "def run_agentic_system(user_query: str):\n",
    "    router = EmbeddingRouter()\n",
    "    agent = router.route(user_query)\n",
    "    return agent.run(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b0833de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Agent called\n",
      "ðŸ“Š EvaluationAgent: Handling evaluation & metrics\n"
     ]
    }
   ],
   "source": [
    "# Example Run\n",
    "query = \"How do I evaluate the performance of a RAG pipeline?\"\n",
    "response = run_agentic_system(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8ee71",
   "metadata": {},
   "source": [
    "# LLM-based routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "467c50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialist Agents\n",
    "\n",
    "class CodeAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Code Agent called\")\n",
    "        return \"ðŸ§‘â€ðŸ’» CodeAgent: Handling code-related tasks\"\n",
    "\n",
    "\n",
    "class RAGAgent:\n",
    "    def run(self, query):\n",
    "        print(\"RAG Agent called\")\n",
    "        return \"ðŸ“š RAGAgent: Handling retrieval-based tasks\"\n",
    "\n",
    "\n",
    "class DesignAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Design Agent called\")\n",
    "        return \"ðŸ—ï¸ DesignAgent: Handling architecture/design tasks\"\n",
    "\n",
    "\n",
    "class EvaluationAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Evaluation Agent called\")\n",
    "        return \"ðŸ“Š EvaluationAgent: Handling evaluation & metrics\"\n",
    "\n",
    "\n",
    "class GeneralAgent:\n",
    "    def run(self, query):\n",
    "        print(\"General Agent called\")\n",
    "        return \"ðŸ¤– GeneralAgent: Handling ambiguous queries\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06794dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-Based Router - OpenAI-style API\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "class LLMRouter:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "\n",
    "        self.agents = {\n",
    "            \"code\": CodeAgent(),\n",
    "            \"rag\": RAGAgent(),\n",
    "            \"design\": DesignAgent(),\n",
    "            \"evaluation\": EvaluationAgent(),\n",
    "            \"general\": GeneralAgent()\n",
    "        }\n",
    "\n",
    "        self.system_prompt = \"\"\"\n",
    "You are an AI router.\n",
    "Your job is to select the most appropriate agent for a user query.\n",
    "\n",
    "Available agents:\n",
    "- code: programming, python, debugging, implementation\n",
    "- rag: retrieval augmented generation, documents, vector databases\n",
    "- design: system architecture, scalable systems\n",
    "- evaluation: metrics, benchmarking, performance evaluation\n",
    "- general: unclear or mixed requests\n",
    "\n",
    "Return ONLY one word from:\n",
    "code, rag, design, evaluation, general\n",
    "\"\"\"\n",
    "\n",
    "    def classify_intent(self, query: str) -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        intent = response.choices[0].message.content.strip().lower()  # Output Validation\n",
    "\n",
    "        if intent not in self.agents:\n",
    "            intent = \"general\"\n",
    "\n",
    "        return intent\n",
    "\n",
    "    # Routing Logic\n",
    "    def route(self, query: str):\n",
    "        intent = self.classify_intent(query)\n",
    "        return self.agents[intent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b421bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Engine\n",
    "\n",
    "def run_agentic_system(user_query: str):\n",
    "    router = LLMRouter()\n",
    "    agent = router.route(user_query)\n",
    "    return agent.run(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff92500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Agent called\n",
      "ðŸ“Š EvaluationAgent: Handling evaluation & metrics\n"
     ]
    }
   ],
   "source": [
    "# Example Run\n",
    "\n",
    "query = \"How do I evaluate the performance of a RAG pipeline?\"\n",
    "response = run_agentic_system(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71095e9b",
   "metadata": {},
   "source": [
    "# Hybrid routing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7564c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialist Agents\n",
    "\n",
    "class CodeAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Code Agent called\")\n",
    "        return \"ðŸ§‘â€ðŸ’» CodeAgent: Handling code-related tasks\"\n",
    "\n",
    "\n",
    "class RAGAgent:\n",
    "    def run(self, query):\n",
    "        print(\"RAG Agent called\")\n",
    "        return \"ðŸ“š RAGAgent: Handling retrieval-based tasks\"\n",
    "\n",
    "\n",
    "class DesignAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Design Agent called\")\n",
    "        return \"ðŸ—ï¸ DesignAgent: Handling architecture/design tasks\"\n",
    "\n",
    "\n",
    "class EvaluationAgent:\n",
    "    def run(self, query):\n",
    "        print(\"Evaluation Agent called\")\n",
    "        return \"ðŸ“Š EvaluationAgent: Handling evaluation & metrics\"\n",
    "\n",
    "\n",
    "class GeneralAgent:\n",
    "    def run(self, query):\n",
    "        print(\"General Agent called\")\n",
    "        return \"ðŸ¤– GeneralAgent: Handling ambiguous queries\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dd0c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-Based Router (Tier 1 â€“ Fast Path)\n",
    "\n",
    "class RuleRouter:\n",
    "    def route(self, query: str):\n",
    "        q = query.lower()\n",
    "\n",
    "        if \"python\" in q or \"code\" in q:\n",
    "            return \"code\"\n",
    "        if \"rag\" in q or \"retrieval\" in q:\n",
    "            return \"rag\"\n",
    "        if \"architecture\" in q or \"design\" in q:\n",
    "            return \"design\"\n",
    "        if \"evaluate\" in q or \"metrics\" in q:\n",
    "            return \"evaluation\"\n",
    "\n",
    "        return None  # No confident match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbde81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding-Based Router (Tier 2 â€“ Semantic Match)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "class EmbeddingRouter:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "        self.intent_descriptions = {\n",
    "            \"code\": \"programming, python, debugging, implementation\",\n",
    "            \"rag\": \"retrieval augmented generation, vector database, documents\",\n",
    "            \"design\": \"system architecture, scalable systems\",\n",
    "            \"evaluation\": \"evaluation metrics, benchmarking, performance\",\n",
    "        }\n",
    "\n",
    "        self.intent_embeddings = {\n",
    "            k: self.model.encode(v, convert_to_tensor=True)\n",
    "            for k, v in self.intent_descriptions.items()\n",
    "        }\n",
    "\n",
    "    def route(self, query: str, threshold: float = 0.45):\n",
    "        query_emb = self.model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        scores = {\n",
    "            intent: util.cos_sim(query_emb, emb).item()\n",
    "            for intent, emb in self.intent_embeddings.items()\n",
    "        }\n",
    "\n",
    "        best_intent, best_score = max(scores.items(), key=lambda x: x[1])\n",
    "\n",
    "        if best_score >= threshold:\n",
    "            return best_intent\n",
    "\n",
    "        return None  # Not confident â†’ escalate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "642ecafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-Based Router (Tier 3 â€“ Reasoning)\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class LLMRouter:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "\n",
    "        self.prompt = \"\"\"\n",
    "You are an AI routing agent.\n",
    "Select the best agent for the user query.\n",
    "\n",
    "Agents:\n",
    "- code\n",
    "- rag\n",
    "- design\n",
    "- evaluation\n",
    "- general\n",
    "\n",
    "Return ONLY one word.\n",
    "\"\"\"\n",
    "\n",
    "    def route(self, query: str):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.prompt},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46a5a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Router (Orchestrator)\n",
    "\n",
    "class HybridRouter:\n",
    "    def __init__(self):\n",
    "        self.rule_router = RuleRouter()\n",
    "        self.embedding_router = EmbeddingRouter()\n",
    "        self.llm_router = LLMRouter()\n",
    "\n",
    "        self.agents = {\n",
    "            \"code\": CodeAgent(),\n",
    "            \"rag\": RAGAgent(),\n",
    "            \"design\": DesignAgent(),\n",
    "            \"evaluation\": EvaluationAgent(),\n",
    "            \"general\": GeneralAgent()\n",
    "        }\n",
    "\n",
    "    def route(self, query: str):\n",
    "        # Tier 1: Rule-based\n",
    "        intent = self.rule_router.route(query)\n",
    "        if intent:\n",
    "            print(\"Routed via Rule-Based Router\")\n",
    "            return self.agents[intent]\n",
    "\n",
    "        # Tier 2: Embedding-based\n",
    "        intent = self.embedding_router.route(query)\n",
    "        if intent:\n",
    "            print(\"Routed via Embedding-Based Router\")\n",
    "            return self.agents[intent]\n",
    "\n",
    "        # Tier 3: LLM-based\n",
    "        intent = self.llm_router.route(query)\n",
    "        print(\"Routed via LLM-Based Router\")\n",
    "        return self.agents.get(intent, self.agents[\"general\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14ab2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Engine\n",
    "\n",
    "def run_agentic_system(query: str):\n",
    "    router = HybridRouter()\n",
    "    agent = router.route(query)\n",
    "    return agent.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a726af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routed via Rule-Based Router\n",
      "RAG Agent called\n",
      "ðŸ“š RAGAgent: Handling retrieval-based tasks\n"
     ]
    }
   ],
   "source": [
    "# Example Run\n",
    "\n",
    "#query = \"How can I benchmark and evaluate a RAG pipeline?\"\n",
    "query = \"How do I evaluate the performance of a RAG pipeline?\"\n",
    "response = run_agentic_system(query)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
