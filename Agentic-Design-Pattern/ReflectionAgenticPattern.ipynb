{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1210f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Query: How to evaluate the RAG?\n",
      "\n",
      "Retrieved Documents: ['RAG retrieves external documents at inference time.', 'Fine-tuning updates model weights using training data.', 'RAG reduces hallucinations by grounding responses.']\n",
      "\n",
      "Initial Answer: RAG uses external documents to answer questions, while fine-tuning changes model parameters.\n",
      "\n",
      "Reflection Issues: ['Missing real-world examples', 'Missing cost comparison']\n",
      "\n",
      "Final Answer: RAG uses external documents to answer questions, while fine-tuning changes model parameters.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Reflection Agentic RAG System\n",
    "# -----------------------------\n",
    "\n",
    "class VectorDB:\n",
    "    def retrieve(self, query, top_k=3):\n",
    "        # Mock retrieval\n",
    "        return [\n",
    "            \"RAG retrieves external documents at inference time.\",\n",
    "            \"Fine-tuning updates model weights using training data.\",\n",
    "            \"RAG reduces hallucinations by grounding responses.\"\n",
    "        ]\n",
    "\n",
    "\n",
    "class LLM:\n",
    "    def generate(self, prompt, context):\n",
    "        # Mock LLM response\n",
    "        return (\n",
    "            \"RAG uses external documents to answer questions, \"\n",
    "            \"while fine-tuning changes model parameters.\"\n",
    "        )\n",
    "\n",
    "    def evaluate(self, answer, context):\n",
    "        # Reflection / self-critique\n",
    "        issues = []\n",
    "\n",
    "        if \"example\" not in answer.lower():\n",
    "            issues.append(\"Missing real-world examples\")\n",
    "\n",
    "        if \"cost\" not in answer.lower():\n",
    "            issues.append(\"Missing cost comparison\")\n",
    "\n",
    "        return issues\n",
    "\n",
    "\n",
    "class ReflectionRAGAgent:\n",
    "    def __init__(self):\n",
    "        self.vector_db = VectorDB()\n",
    "        self.llm = LLM()\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        return self.vector_db.retrieve(query)\n",
    "\n",
    "    def generate(self, query, docs):\n",
    "        return self.llm.generate(query, docs)\n",
    "\n",
    "    def reflect_and_adjust(self, issues, query):\n",
    "        # Modify query or strategy based on reflection\n",
    "        if issues:\n",
    "            query += \" Include examples and cost trade-offs.\"\n",
    "        return query\n",
    "\n",
    "    def run(self, user_query):\n",
    "        print(\"\\nUser Query:\", user_query)\n",
    "\n",
    "        # Step 1: Retrieve\n",
    "        documents = self.retrieve(user_query)\n",
    "        print(\"\\nRetrieved Documents:\", documents)\n",
    "\n",
    "        # Step 2: Generate\n",
    "        answer = self.generate(user_query, documents)\n",
    "        print(\"\\nInitial Answer:\", answer)\n",
    "\n",
    "        # Step 3: Evaluate (Reflection)\n",
    "        issues = self.llm.evaluate(answer, documents)\n",
    "        print(\"\\nReflection Issues:\", issues)\n",
    "\n",
    "        # Step 4: Reflect & Adjust\n",
    "        if issues:\n",
    "            updated_query = self.reflect_and_adjust(issues, user_query)\n",
    "            documents = self.retrieve(updated_query)\n",
    "            answer = self.generate(updated_query, documents)\n",
    "\n",
    "        # Step 5: Finalize\n",
    "        print(\"\\nFinal Answer:\", answer)\n",
    "        return answer\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Run the Agent\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    agent = ReflectionRAGAgent()\n",
    "    #agent.run(\"Explain RAG vs fine-tuning\")\n",
    "    agent.run(\"How to evaluate the RAG?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
